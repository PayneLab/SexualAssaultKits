{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChiSquareExample",
      "provenance": [],
      "collapsed_sections": [
        "zrHVHGjYOEOj",
        "AmdZJtmvk9FS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devorahst/Test/blob/main/ChiSquareExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2y3xZZN3oIp"
      },
      "source": [
        "#**Chi-Square Test of Independence**\n",
        "In this walkthrough, we will go over an example of using Chi-Square Test of Independence to establish association between two of the features from our SAK datset. We will be using the feature 'DNAKitUsed' and our dependent variable, 'CODISNDISeligibleProfile'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrHVHGjYOEOj"
      },
      "source": [
        "# Part 1. Set-Up\n",
        "First, we must download the dataset. Upon running the cell, you will be prompted to login to your Gmail account. You will then be provided with a one-time use code to copy and paste into the slot below. After hitting enter, the dataset will load into this script.\n",
        "\n",
        "*See [IO Notebook](https://colab.research.google.com/drive/1fuF8iahEqBFV62Y6OoiEViUqHo-DbXrT) for more information about set-up and interacting with our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_29x6D939k8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ca70018e-b4f4-48ac-c1e4-2bbf0659f427"
      },
      "source": [
        "#pulls up our SAK dataset\n",
        "#@title Upload Dataset\n",
        "file_id = \"13DLmmbYXonl9alHR4VobfeTuA_IxlQxZ\" #@param {type:\"string\"}\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  _, done = downloader.next_chunk()\n",
        "\n",
        "fileId = drive.CreateFile({'id': file_id }) #DRIVE_FILE_ID is file id example: 1iytA1n2z4go3uVCwE_vIKouTKyIDjEq\n",
        "print(fileId['title'])  \n",
        "fileId.GetContentFile(fileId['title'])  # Save Drive file as a local file\n",
        "\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# To change scientific numbers to float\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "\n",
        "with open(fileId['title'], encoding=\"utf8\", errors='ignore') as f:\n",
        "  df = pd.read_csv(f)\n",
        "\n",
        "df = df.apply(pd.to_numeric, errors='ignore')\n",
        "predictedVariable = \"CODISNDISeligibleProfile\"\n",
        "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
        "df = df.replace({np.nan: \"No Response\"})\n",
        "df = df.applymap(str)\n",
        "\n",
        "#delete rows that don't have a value for CODISNDISeligibleProfile\n",
        "df = df[df[predictedVariable] != \"No Response\"]\n",
        "\n",
        "predictedFeatures = ['CODISNDISeligibleProfile', 'SDISeligibleprofile']  \n",
        "\n",
        "numericalFeatures = ['Age', 'Timebetweenassaultandexaminhours', 'PainLevel', 'MulitipleSuspectNumber', \n",
        "                     'NumberofUnknownresponses', 'NumberAssaultiveActs', 'Numberofphysicalinjuries', 'Numberofgentialinjuries',\n",
        "                     'NumberOFitemsTested', 'TimeBetweenCollectAndDNAext', 'TimeBetweenSubmissionANDtesting', 'NumberOfswabsQuantMaleDNA',\n",
        "                     'NumberOfswabsDNAanalysis', 'NumberofSTRDNAloci', 'NumberOFswabsSTRDNAprofile', 'NumberOfYSTRDNAloci']\n",
        "\n",
        "categoricalFeatures = ['Site', 'EXAMbySANE', 'YearKitCollected', 'KITbroughtTOcrimelab', 'KITlengthofSubmissionTime',\n",
        "                       'UnderAge18', 'Gender', 'ExamDeclined', 'Noninterview', 'Race', 'PriorHxofSAover14',\n",
        "                       'PriorHxofSAunder14', 'Student', 'Military', 'Pain', 'PainLocation1','PainLocation2', \n",
        "                       'PainLocation3', 'PainLocation4','PainTreatment', 'PermanentAddress', 'CurrentPhysicalmedprob',\n",
        "                       'MedProbChronic', 'MedProbInfection', 'MedProbBlood', 'MedProbCardiac', 'MedProbEar', 'MedProbEndocrine',\n",
        "                       'MedProbEye', 'MedProbGI', 'MedProbGU', 'MedProbGYN', 'MedProbImmune', 'MedProbMusculoskeletal', 'MedProbNeurological',\n",
        "                       'MedProbOral', 'MedProbRenal', 'MedProbRespiratory', 'MedProbSkin', 'MedProbOther', 'Medication',\n",
        "                       'PsychotropicMEDuse', 'PsychotropicANTIPSYCHOTICSatypical', 'PsychotropicSTIMULANTuse', 'PsychotropicANTIANXIETY', \n",
        "                       'PsychotropicANTIDEPRESSANTS', 'PsychotropicANTISEIZUREbipolar', 'PsychotropicADDICTIONmeds','PsychotropicSLEEPaid', 'PsychotropicOTHER', \n",
        "                       'PsychotropicANTIPSYCHOTICStypical', 'PolypharmacyPsychMeds', 'ImmunizationstatusTETANUS', 'ReceivedTetanus',\n",
        "                       'ImmunizationstatusHEP', 'ReceivedHepB', 'Sexualcontactwithin120hours', 'Selfdisclosurementalillness', 'MIdepression',\n",
        "                       'MIanxiety', 'MIPTSD', 'MIpsychoticDisorders', 'MIadhd', 'MIpersonalitydisorder', 'MIbipolar', 'MIeatingdisorder', 'MIdrugalcoholdisorders', \n",
        "                       'MIother', 'SelfDiscolsureMentalillnessORuseofpsychotropics', 'OnlineMeetingOFsuspect', 'Suspectrelationship',\n",
        "                       'Locationofassault', 'PatientActionScratch', 'PatientActionBite', 'PatientActionHit', 'PatientActionKick', 'PatientActionOther',\n",
        "                       'Suspectrace', 'SuspectactionVERBAL', 'SuspectactionsGRABBEDHELD', 'SuspectactionsPHYSICALBLOWS', 'SuspectactionsSTRANGLEDCHOKED',\n",
        "                       'SuspectactionsWEAPON', 'SuspectactionsRESTRAINTS', 'SuspectactionsBURNED', 'MultipleSuspects', 'SuspectedDrugfacilitated',\n",
        "                       'Patientdruguse', 'PatientETOHuse', 'Suspectdruguse', 'SuspectETOHuse', 'PatientSuspectETOHordrug', 'LossOFconsciousnessORawareness',\n",
        "                       'OneORmoreunknownanswer', 'Unknownanswerto4ormorequestions', 'UnknownanswertoALL', 'AsleepANDawakenedtoassault', 'MemoryLoss',\n",
        "                       'LossOfconsciousness', 'DecreasedAwareness', 'TonicImmobility', 'Detachment', 'NOSApatientsVAGINApenis', 'NOSApatientsVAGINAfingerhand',\n",
        "                       'NOSApatientsVAGINAmouth', 'NOSApatientsVAGINAobject', 'NOSApatientsANUSpenis', 'NOSApatientsANUSfingerhand', 'NOSApatientsANUSmouth', \n",
        "                       'NOSApatientsANUSobject', 'NOSApatientsPENISgenitals', 'NOSApatientsPENISfinger', 'NOSApatientsPENISmouth', 'NOSApatientsPENISobject', \n",
        "                       'NOSApatientsMOUTHpenis', 'NOSApatientsMOUTHfinger', 'NOSApatientsMOUTHmouth', 'NOSApatientsMOUTHobject', 'SUSPECTmouthcontactGENITALS', \n",
        "                       'SUSPECTmouthcontactMOUTH', 'SUSPECTmouthcontactOTHER', 'SUSPECTmouthcontactOTHERsite', 'HANDSofSuspectBreast', 'HANDSofSuspectExtremities', \n",
        "                       'HANDSofSuspectOther', 'Ejaculation', 'CONDOMuse', 'LUBRICATIONuse', 'SuspectWASHEDpatient', 'SuspectINJUREDbypatient', 'PostassaultURINATED', \n",
        "                       'PostassaultDEFECATED', 'PostassaultDOUCHED', 'PostassaultVOMITED', 'PostassaultGARGLED', 'PostassaultBRUSHEDTEETH', 'PostassaultATEdrank', \n",
        "                       'PostassaultBATHED', 'PostassaultGENITALWIPE', 'PostassaultCHANGEDCLOTHING', 'PostassaultREMOVEDInserted', 'PhysicalORmentalimpairment', 'Physicalinjury', \n",
        "                       'LPIhead', 'LPIneck', 'LPIbreasts', 'LPIchestback', 'LPIabdomen', 'LPIextremities', 'TPIlaceration', 'TPIecchymosis', 'TPIabrasion', 'TPIredness', \n",
        "                       'TPIswelling', 'TPIbruise', 'TPIpetechiae', 'TPIincision', 'TPIavulsion', 'TPIdiscoloredmark', 'TPIpuncturewound', 'TPIfracture', \n",
        "                       'TPIbitemark', 'TPIburn', 'TPImissingorbrokenTEETH', 'TPIconjunctivalhemorrhage', 'Genitalinjury', 'LGIinnerthighs', 'LGIclitoralhoodclitoris', \n",
        "                       'LGIlabiamajora', 'LGIlabiaminora', 'LGIperiurethraltissueURETHRA', 'LGIperihymenaltissue', 'LGIhymen', 'LGIvagina', 'LGIcervix', 'LGIfossanavicularis', \n",
        "                       'LGIposteriorfourchette', 'LGIperineum', 'LGIperineum', 'LGIanalrectal', 'LGIbuttocks', 'LGImalePerianalperineum', 'LGIglanspenis', 'LGIpenileshaft', \n",
        "                       'LGImaleURETHRALmeatus', 'LGIscrotum', 'LGItestes', 'LGImaleanus', 'LGImalerectum', 'TGIlaceration', 'TGIecchymosis', 'TGIabrasion', 'TGIredness', \n",
        "                       'TGIswelling', 'TGIbruise', 'TGIpetechiae', 'TGIincision', 'TGIavulsion', 'TGIdiscoloredmark', 'TGIpuncturewound', 'ToludineDYEuptake', 'HIVnPEP', \n",
        "                       'UQuikcollected', 'Yscreen', 'NumberItemsWITH3cutoff', 'ItemsAnalyzed1', 'ItemsAnalyzed2', 'ItemsAnalyzed3', 'ItemsAnalyzed4', 'ItemsAnalyzed5', \n",
        "                       'ItemsAnalyzed6', 'ItemsAnalyzed7', 'ItemsAnalyzed8', 'ItemsAnalyzed9', 'ItemsAnalyzed10', 'TypesOFitemsTested', 'RandomSample20142015', \n",
        "                       'YearofDNAextraction', 'LocationOfTesting','DANYfundedSAK', 'DNAKitUsed', 'SerologyDoneBeforeDNA', 'QuantMaleDNAFound', 'QuantMaleSwabLoc1', \n",
        "                       'QuantMaleSwabLoc2', 'QuantMaleSwabLoc3', 'QuantMaleSwabLoc4', 'QuantMaleSwabLoc5', 'Swab1ToDNAanalysis', 'Swab2ToDNAanalysis', \n",
        "                       'Swab3ToDNAanalysis', 'Swab4ToDNAanalysis', 'ProbableSTRDNAprofileOFsuspect', 'ProfileofSTRDNAloci', 'ProbableYSTRDNAprofile', 'ProfileOfYSTRDNAloci', \n",
        "                       'SwabLocationYSTRDNA', 'SecondSwabLocationYSTRDNA', 'SwabFromSuspectwithVictimDNA', 'ExcludeSuspect', 'ConsensualPartnerStandardSubmitted', \n",
        "                       'STRDNAProbableprofileTYPE', 'CODISprofileHit', 'STRDNAkitUsed', 'SUSPECTmouthcontactBREASTS', 'Swab1LocationSTRDNAprofile', 'Swab2LocationSTRDNAprofile',\n",
        "                       'Swab3LocationSTRDNAprofile', 'SuspectStandardSubmitted', 'CODISNDISreasons', 'CODISSDISreasons']\n",
        "\n",
        "#unusedFeatures and stringFeatures are columns that contain data that was relevant to medical professionals and for legal purposes, \n",
        "#but that aren't useful for our feature association or for predicting eligibility\n",
        "unusedFeatures = ['filter_$', 'PainTreatmentYesNo', 'GenderMaleFemale', 'DVsuspect', 'RacePrimaryGroups', 'IPSAcombined', 'STRDNAcompleted', \n",
        "                  'PhysicalInjuryNOunknown', 'GenitalInjuryNOunknown']\n",
        "\n",
        "stringFeatures = ['DeIdentifiedCase', 'Raceother', 'SchoolName', 'MilitaryBranchName', 'AddressIfnotPermanent', 'Currentmedprobtext',\n",
        "                  'MedProbOtherText', 'Medicationtext', 'Sexualcontactwithin120hoursTYPE', 'SelfdisclosureMItype', 'OnlineMeetingName', 'SuspectrelationshipOTHER',\n",
        "                  'LocationofassaultOTHER', 'Surfaceofassault', 'PatientActionOtherTEXT', 'SuspectraceOTHER', 'SuspectOTHERactions', 'NOSApatientsVAGINAobjectdescription',\n",
        "                  'NOSApatientsANUSobjectdescription', 'NOSApatientsPENISobjectdescription', 'NOSApatientsMOUTHobjectdescription', 'EjaculationSITE', 'LUBRICATIONtype',\n",
        "                  'SuspectINJUREDbypatientexplanation', 'Impairmentdescription', 'UBFSnumber', 'ISPnumber', 'DateSubmittedUBFS', 'DateofDNAextractionReport',\n",
        "                  'BodySwabLocQuant', 'BodySwabDNAanalysis', 'BodySwabLocationSTRDNA', 'BodySwabYSTRDNA', 'ISPnotes2020', 'UBFSnotes2020', 'UBFSnotes2018', 'UBFSnotes2014']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MasterValentine_UpdatedCODIS_Feb12_2021.csv\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,9,301) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-iX_I9dq0H"
      },
      "source": [
        "#Part 2. Chi-Square\n",
        "Now we can run our chi-square test. We do this by first finding our bonferroni correction for our p-value cutoff of significance, then create our contingency table, and finally use our table in a chi-square model. \n",
        "\n",
        "1. Explanation of the Bonferroni Correction\n",
        "2. Contingency Table \n",
        "3. Chi Square Test and Walkthrough of our Findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmdZJtmvk9FS"
      },
      "source": [
        "###Bonferroni Correction\n",
        "If we only had one hypothesis to test (i.e. the association of one feature to our predicted variable), we could safely use an alpha value of .05. But because we are comparing 314 separate features, the risk of a type 1 error (falsely rejecting our null hypothesis of two features having no significant association) occurring is increased. We can correct for this by using the Bonferroni Correction. We calculate this by taking our desired alpha level of .05 and dividing it by the total number of hypotheses used (or features we are comparing). In this example, we will use .05/314 to receive a p-value cutoff of 1.592357e-04. That means that any p-values we calculate above this cutoff are not significant and we will fail to reject our null hypothesis that the given feature is not associated with an eligible profile. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FtR4FcyRcg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "00b1fa1b-06b0-4ed4-9e01-fa5f5ae75448"
      },
      "source": [
        "#@title Bonferroni Cutoff\n",
        "#Bonferroni cutoff of significance \n",
        "scientific_notation = \"{:e}\".format(12300000)\n",
        "\n",
        "print(\"The Bonferroni cutoff is \" + \"{:e}\".format(.05/len(df.columns)) + \". Features with p-values above this are not significant.\")\n",
        "#Number of features considered\n",
        "print(\"There are\", str(len(df.columns)), \"features being considered.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Bonferroni cutoff is 1.592357e-04. Features with p-values above this are not significant.\n",
            "There are 314 features being considered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU-7F5SBY3T9"
      },
      "source": [
        "### Example Contingency Table\n",
        " A contingency table is an arrangement that shows the relation between two features. Rows of the contingency table show the different categories for one of the features while the categories for the other feature are presented by the columns. Cell values show the count of total cases for each combination of categories. In this case, we are comparing the type of DNAKitUsed to obtaining a CODISNDISeligibleProfile. Below are the keys taken from the [code book](https://docs.google.com/document/d/18PDTuK0lshc193lXA3b7UDgcRzMoEEGA/edit?rtpof=true) for the features DNAKitUsed and CODISNDISeligibleProfile. In this example, we will try to find if the type of DNA kit used is strongly associated with an eligible profile result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBxTEnlwZtbv"
      },
      "source": [
        "**Key for DNAKitUsed**\n",
        "*   1 = ID+\n",
        "*   2 = Yfiler\n",
        "*   3 = Both ID+ and Yfiler\n",
        "*   4 = Globalfiler\n",
        "*   5 = Globalfiler and Yfiler\n",
        "*   6 = None\n",
        "*   7 = Promega STR\n",
        "*   8 = Promega YSTR\n",
        "*   9 = Promega STR and YSTR\n",
        "*   No Response = Data not collected in exam or not reported\n",
        "\n",
        "**Numeric Key for CODISNDISeligibleProfile**\n",
        "*   0 = No (Not an eligible profile)\n",
        "*   1 = Yes, uploaded (Is an eligible profile)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q01t5ALiWLUR",
        "cellView": "code",
        "outputId": "612be7e0-b4c1-4baf-937d-bc0a329da3e9"
      },
      "source": [
        "contigency= pd.crosstab(df['DNAKitUsed'], df[predictedVariable]) \n",
        "# contigency = contigency.drop(index='2')\n",
        "# contigency = contigency.drop(index='3')\n",
        "# contigency = contigency.drop(index='5')\n",
        "# contigency = contigency.drop(index='6')\n",
        "# contigency = contigency.drop(index='9')\n",
        "# contigency = contigency.drop(index='No Response')\n",
        "\n",
        "print(contigency)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CODISNDISeligibleProfile     0     1\n",
            "DNAKitUsed                          \n",
            "1                          134   229\n",
            "2                          159    17\n",
            "3                          202   254\n",
            "4                         1194  1027\n",
            "5                           19    18\n",
            "6                         1392     3\n",
            "7                          246   299\n",
            "9                            1     0\n",
            "No Response                449     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhgr1gJy_mVM"
      },
      "source": [
        "Using the contingency table, it is easier to see big differences between eligible and noneligible profiles for each kit type. We aren't as interested in results for row 9 due to small sample size or the \"No Response\" row, but a kit coded as 2 or 6 stands out as not producing many eligible CODISNDIS profiles. If we take a look at what these two rows actually code for, we see that a 2 represents the use of a YFiler kit and 6 codes for no kit being used. It makes sense that if no kit were used, we wouldn't expect to get a profile hit. However, we may want to look more into the use of a YFiler kit to see why this kit doesn't seem to produce many eligible profiles.\n",
        "\n",
        "Overall, any of these factors could influence whether our feature of DNAKitUsed returns a significant p-value when we run our Chi-Square Test. We should keep this in mind as we continue our analysis of our dataset (And maybe run Pairwise testing to look into how each kit type affects our p-value). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6KtoPkSqwFs"
      },
      "source": [
        "###Example of Chi-Square and Explanation of Our Findings \n",
        "\n",
        "Using the scipy.stats.chi2_contingency function, we can easily find the p-value assigned to the association between our two features. This function also returns the test statistic used, the degrees of freedom necessary to calculate our result, and the expected frequencies based on the marginal sums of our table. For our purposes, we really only care about the p-value that is returned from this function. If our p-value is less than our bonferroni correction value of 1.592357e-04, we reject our null hypothesis that DNAKitUsed and CODISNDISeligibleProfile are not associated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kHPUKINMLbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ed36ac-9cf5-4524-c03c-6bd9b41f1047"
      },
      "source": [
        "#c - the test statistic\n",
        "#p - the probability\n",
        "#dof - degrees of freedom\n",
        "#expected - The expected frequencies, based on the marginal sums of the table.\n",
        "\n",
        "cutoff = 0.05 / len(df.columns)\n",
        "c, p, dof, expected = chi2_contingency(contigency) \n",
        "if (p < cutoff):\n",
        "  print(str(p) + \" is less than 1.592357e-04.\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.486807150240603e-258 is less than 1.592357e-04.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOSTbNFFiBrW"
      },
      "source": [
        "The P-Value we obtained from our Chi-Square was less than our cutoff value, so we reject our null hypothesis. That means that we can assume that the feature DNAKitUsed is associated with the feature CODISNDISeligibleProfile. As noted before, we would probably want to take this feature and dig deeper with Pairwise testing to note which categories have the strongest pull towards obtaining this significant p-value. "
      ]
    }
  ]
}